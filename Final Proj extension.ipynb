{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e749cf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sets Defined ---\n",
      "Products: ['Product 1', 'Product 2']\n",
      "Manufacturers: ['CAM', 'LEV', 'LETH']\n",
      "Distribution Centers: ['CORN', 'SUR', 'CAL', 'VAU']\n",
      "Stores: ['MONT', 'NEW', 'KEL']\n",
      "\n",
      "--- Mappings ---\n",
      "Manufacturer Mappings: {'CAM': 1, 'LEV': 2, 'LETH': 3}\n",
      "DC Mappings: {'CORN': 1, 'SUR': 2, 'CAL': 3, 'VAU': 4}\n",
      "Store Mappings: {'MONT': 1, 'NEW': 2, 'KEL': 3}\n",
      "Product Mappings: {'Product 1': 1, 'Product 2': 2}\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'cost_mfg_product.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProduct Mappings: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproduct_name_to_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# --- 2. Load Data Parameters from CSVs ---\u001b[39;00m\n\u001b[32m     47\u001b[39m \n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# Production Cost (c_ij): Cost to produce item 'i' at manufacturer 'j'\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m df_production_cost = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcost_mfg_product.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m production_cost = {}\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m df_production_cost.iterrows():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/VE/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/VE/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/VE/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/VE/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/VE/.venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'cost_mfg_product.csv'"
     ]
    }
   ],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1. Define Sets and Mappings ---\n",
    "# These sets will be populated dynamically from the CSV headers/indices\n",
    "# Mappings are crucial for linking string names from CSVs to numerical IDs for Gurobi\n",
    "\n",
    "# Manufacturers (from fixedcost_manu_to_dc.csv columns)\n",
    "# DCs (from fixedcost_manu_to_dc.csv rows and fixedcost_dc_to_store.csv columns)\n",
    "# Stores (from store_demand_data.csv rows and fixedcost_dc_to_store.csv rows)\n",
    "# Products (from store_demand_data.csv columns and variablecost_manu_to_dc_prodX.csv filenames)\n",
    "\n",
    "# Manually define mappings based on expected CSV content\n",
    "# This ensures consistent IDs even if a CSV is missing a specific entry.\n",
    "mfg_name_to_id = {'CAM': 1, 'LEV': 2, 'LETH': 3}\n",
    "id_to_mfg_name = {v: k for k, v in mfg_name_to_id.items()}\n",
    "MANUFACTURERS = list(mfg_name_to_id.keys()) # Use names for sets for clarity in loops\n",
    "\n",
    "dc_name_to_id = {'CORN': 1, 'SUR': 2, 'CAL': 3, 'VAU': 4}\n",
    "id_to_dc_name = {v: k for k, v in dc_name_to_id.items()}\n",
    "DCS = list(dc_name_to_id.keys())\n",
    "\n",
    "store_name_to_id = {'MONT': 1, 'NEW': 2, 'KEL': 3}\n",
    "id_to_store_name = {v: k for k, v in store_name_to_id.items()}\n",
    "STORES = list(store_name_to_id.keys())\n",
    "\n",
    "product_name_to_id = {'Product 1': 1, 'Product 2': 2}\n",
    "id_to_product_name = {v: k for k, v in product_name_to_id.items()}\n",
    "PRODUCTS = list(product_name_to_id.keys())\n",
    "\n",
    "\n",
    "print(\"--- Sets Defined ---\")\n",
    "print(f\"Products: {PRODUCTS}\")\n",
    "print(f\"Manufacturers: {MANUFACTURERS}\")\n",
    "print(f\"Distribution Centers: {DCS}\")\n",
    "print(f\"Stores: {STORES}\\n\")\n",
    "\n",
    "print(\"--- Mappings ---\")\n",
    "print(f\"Manufacturer Mappings: {mfg_name_to_id}\")\n",
    "print(f\"DC Mappings: {dc_name_to_id}\")\n",
    "print(f\"Store Mappings: {store_name_to_id}\")\n",
    "print(f\"Product Mappings: {product_name_to_id}\\n\")\n",
    "\n",
    "\n",
    "# --- 2. Load Data Parameters from CSVs ---\n",
    "\n",
    "# Production Cost (c_ij): Cost to produce item 'i' at manufacturer 'j'\n",
    "df_production_cost = pd.read_csv('cost_mfg_product.csv')\n",
    "production_cost = {}\n",
    "for index, row in df_production_cost.iterrows():\n",
    "    mfg_id = mfg_name_to_id.get(row['MFG'])\n",
    "    for col in ['Product 1', 'Product 2']:\n",
    "        product_id = product_name_to_id.get(col)\n",
    "        if mfg_id is not None and product_id is not None:\n",
    "            production_cost[(product_id, mfg_id)] = row[col]\n",
    "\n",
    "\n",
    "# Manufacturer Capacity (cap_j): Maximum total production for each manufacturer\n",
    "# NOTE: This data was not in a provided CSV, so it remains hardcoded.\n",
    "manufacturer_capacity = {\n",
    "    mfg_name_to_id['CAM']: 151000,\n",
    "    mfg_name_to_id['LEV']: 91000,\n",
    "    mfg_name_to_id['LETH']: 61000,\n",
    "}\n",
    "\n",
    "# DC Capacity (cap_k): Maximum total throughput for each distribution center\n",
    "# NOTE: This data was not in a provided CSV, so it remains hardcoded.\n",
    "dc_capacity = {\n",
    "    dc_name_to_id['CORN']: 111000,\n",
    "    dc_name_to_id['SUR']: 95000,\n",
    "    dc_name_to_id['CAL']: 63000,\n",
    "    dc_name_to_id['VAU']: 48000,\n",
    "}\n",
    "\n",
    "# Store Capacity (cap_e): Maximum total throughput for each store\n",
    "# NOTE: This data was not in a provided CSV, so it remains hardcoded.\n",
    "store_capacity = {\n",
    "    store_name_to_id['MONT']: 75000,\n",
    "    store_name_to_id['NEW']: 77000,\n",
    "    store_name_to_id['KEL']: 61000,\n",
    "}\n",
    "\n",
    "\n",
    "# Fixed Cost Manufacturer-DC (fixed_manu_dc_jk)\n",
    "df_fixed_manu_dc = pd.read_csv('fixedcost_manu_to_dc.csv')\n",
    "fixed_manu_dc_cost = {}\n",
    "# Assuming the first column is unnamed and contains DC names\n",
    "df_fixed_manu_dc.rename(columns={df_fixed_manu_dc.columns[0]: 'DC_Name'}, inplace=True)\n",
    "for index, row in df_fixed_manu_dc.iterrows():\n",
    "    dc_id = dc_name_to_id.get(row['DC_Name'])\n",
    "    for col_name in df_fixed_manu_dc.columns[1:]:\n",
    "        mfg_id = mfg_name_to_id.get(col_name)\n",
    "        if mfg_id is not None and dc_id is not None:\n",
    "            fixed_manu_dc_cost[(mfg_id, dc_id)] = row[col_name]\n",
    "\n",
    "\n",
    "# Variable Cost Manufacturer-DC (var_manu_dc_ijk)\n",
    "var_manu_dc_cost = {}\n",
    "for prod_name, prod_id in product_name_to_id.items():\n",
    "    prod_file_suffix = 'prod1.csv' if prod_name == 'Product 1' else 'prod2.csv'\n",
    "    df_var_manu_dc = pd.read_csv(f'variablecost_manu_to_dc_{prod_file_suffix}')\n",
    "    df_var_manu_dc.rename(columns={df_var_manu_dc.columns[0]: 'DC_Name'}, inplace=True)\n",
    "    for index, row in df_var_manu_dc.iterrows():\n",
    "        dc_id = dc_name_to_id.get(row['DC_Name'])\n",
    "        for col_name in df_var_manu_dc.columns[1:]:\n",
    "            mfg_id = mfg_name_to_id.get(col_name)\n",
    "            if dc_id is not None and mfg_id is not None:\n",
    "                var_manu_dc_cost[(prod_id, mfg_id, dc_id)] = row[col_name]\n",
    "\n",
    "\n",
    "# Fixed Cost DC-Store (fixed_dc_store_ke)\n",
    "df_fixed_dc_store = pd.read_csv('fixedcost_dc_to_store.csv')\n",
    "fixed_dc_store_cost = {}\n",
    "df_fixed_dc_store.rename(columns={df_fixed_dc_store.columns[0]: 'Store_Name'}, inplace=True)\n",
    "for index, row in df_fixed_dc_store.iterrows():\n",
    "    store_id = store_name_to_id.get(row['Store_Name'])\n",
    "    for col_name in df_fixed_dc_store.columns[1:]:\n",
    "        dc_id = dc_name_to_id.get(col_name)\n",
    "        if store_id is not None and dc_id is not None:\n",
    "            fixed_dc_store_cost[(dc_id, store_id)] = row[col_name]\n",
    "\n",
    "\n",
    "# Variable Cost DC-Store (var_dc_store_ike)\n",
    "var_dc_store_cost = {}\n",
    "for prod_name, prod_id in product_name_to_id.items():\n",
    "    prod_file_suffix = 'prod1.csv' if prod_name == 'Product 1' else 'prod2.csv'\n",
    "    df_var_dc_store = pd.read_csv(f'variablecost_dc_to_store_{prod_file_suffix}')\n",
    "    df_var_dc_store.rename(columns={df_var_dc_store.columns[0]: 'Store_Name'}, inplace=True)\n",
    "    for index, row in df_var_dc_store.iterrows():\n",
    "        store_id = store_name_to_id.get(row['Store_Name'])\n",
    "        for col_name in df_var_dc_store.columns[1:]:\n",
    "            dc_id = dc_name_to_id.get(col_name)\n",
    "            if store_id is not None and dc_id is not None:\n",
    "                var_dc_store_cost[(prod_id, dc_id, store_id)] = row[col_name]\n",
    "\n",
    "\n",
    "# Store Demand (demand_ie)\n",
    "df_store_demand = pd.read_csv('store_demand_data.csv')\n",
    "store_demand = {}\n",
    "for index, row in df_store_demand.iterrows():\n",
    "    store_id = store_name_to_id.get(row['Store_ID'])\n",
    "    if store_id is not None:\n",
    "        store_demand[(product_name_to_id['Product 1'], store_id)] = row['Product 1 Demand']\n",
    "        store_demand[(product_name_to_id['Product 2'], store_id)] = row['Product 2 Demand']\n",
    "\n",
    "\n",
    "# A sufficiently large number for Big-M constraints\n",
    "# This links binary variables (route open/closed) to continuous flow variables.\n",
    "BIG_M = 1000000\n",
    "\n",
    "print(\"--- Data Parameters Loaded from CSVs (and hardcoded where necessary) --- \\n\")\n",
    "\n",
    "\n",
    "# --- 3. Create Gurobi Model ---\n",
    "model = gp.Model(\"SimplifiedSupplyChain\")\n",
    "\n",
    "# --- 4. Define Decision Variables ---\n",
    "\n",
    "# x_ij: Quantity of product 'i' produced by manufacturer 'j'\n",
    "x_ij = model.addVars(product_name_to_id.values(), mfg_name_to_id.values(), name=\"production\", vtype=GRB.CONTINUOUS, lb=0.0)\n",
    "\n",
    "# trans_ijk: Quantity of product 'i' shipped from manufacturer 'j' to DC 'k'\n",
    "trans_ijk = model.addVars(product_name_to_id.values(), mfg_name_to_id.values(), dc_name_to_id.values(), name=\"manu_to_dc_flow\", vtype=GRB.CONTINUOUS, lb=0.0)\n",
    "\n",
    "# trans_ike: Quantity of product 'i' shipped from DC 'k' to store 'e'\n",
    "trans_ike = model.addVars(product_name_to_id.values(), dc_name_to_id.values(), store_name_to_id.values(), name=\"dc_to_store_flow\", vtype=GRB.CONTINUOUS, lb=0.0)\n",
    "\n",
    "# y_jk: Binary variable, 1 if route from manufacturer 'j' to DC 'k' is open, 0 otherwise\n",
    "y_jk = model.addVars(mfg_name_to_id.values(), dc_name_to_id.values(), name=\"manu_dc_route_open\", vtype=GRB.BINARY)\n",
    "\n",
    "# z_ke: Binary variable, 1 if route from DC 'k' to store 'e' is open, 0 otherwise\n",
    "z_ke = model.addVars(dc_name_to_id.values(), store_name_to_id.values(), name=\"dc_store_route_open\", vtype=GRB.BINARY)\n",
    "\n",
    "#NEW BINARY DECISION VARIABLES FOR PROMOTIONS\n",
    "for i in product_name_to_id.values():\n",
    "    promo = model.addVar(vtype=GRB.BINARY, name=f\"promo_{i}\")\n",
    "\n",
    "print(\"--- Decision Variables Defined --- \\n\")\n",
    "\n",
    "# --- 5. Set Objective Function ---\n",
    "# Objective: Minimize Total Cost\n",
    "# Total Cost = Production Cost + Fixed Manu-DC Cost + Fixed DC-Store Cost +\n",
    "#              Variable Manu-DC Transport Cost + Variable DC-Store Transport Cost\n",
    "\n",
    "# Component 1: Production Cost\n",
    "# Sum over all products (i) and manufacturers (j): x_ij * production_cost[i,j]\n",
    "obj_production_cost = gp.quicksum(\n",
    "    x_ij[prod_id, mfg_id] * production_cost[prod_id, mfg_id]\n",
    "    for prod_id in product_name_to_id.values() for mfg_id in mfg_name_to_id.values()\n",
    ")\n",
    "\n",
    "# Component 2: Fixed Cost for Manufacturer-DC routes\n",
    "# Sum over all manufacturers (j) and DCs (k): fixed_manu_dc_cost[j,k] * y_jk[j,k]\n",
    "obj_fixed_manu_dc_cost = gp.quicksum(\n",
    "    fixed_manu_dc_cost[mfg_id, dc_id] * y_jk[mfg_id, dc_id]\n",
    "    for mfg_id in mfg_name_to_id.values() for dc_id in dc_name_to_id.values()\n",
    ")\n",
    "\n",
    "# Component 3: Fixed Cost for DC-Store routes\n",
    "# Sum over all DCs (k) and stores (e): fixed_dc_store_cost[k,e] * z_ke[k,e]\n",
    "obj_fixed_dc_store_cost = gp.quicksum(\n",
    "    fixed_dc_store_cost[dc_id, store_id] * z_ke[dc_id, store_id]\n",
    "    for dc_id in dc_name_to_id.values() for store_id in store_name_to_id.values()\n",
    ")\n",
    "\n",
    "# Component 4: Variable Transportation Cost Manufacturer-DC\n",
    "# Sum over all products (i), manufacturers (j), and DCs (k):\n",
    "# var_manu_dc_cost[i,j,k] * trans_ijk[i,j,k]\n",
    "obj_variable_manu_dc_cost = gp.quicksum(\n",
    "    var_manu_dc_cost[prod_id, mfg_id, dc_id] * trans_ijk[prod_id, mfg_id, dc_id]\n",
    "    for prod_id in product_name_to_id.values() for mfg_id in mfg_name_to_id.values() for dc_id in dc_name_to_id.values()\n",
    ")\n",
    "\n",
    "# Component 5: Variable Transportation Cost DC-Store\n",
    "# Sum over all products (i), DCs (k), and stores (e):\n",
    "# var_dc_store_cost[i,k,e] * trans_ike[i,k,e]\n",
    "obj_variable_dc_store_cost = gp.quicksum(\n",
    "    var_dc_store_cost[prod_id, dc_id, store_id] * trans_ike[prod_id, dc_id, store_id]\n",
    "    for prod_id in product_name_to_id.values() for dc_id in dc_name_to_id.values() for store_id in store_name_to_id.values()\n",
    ")\n",
    "\n",
    "# Set the overall objective to minimize the sum of all cost components\n",
    "'''model.setObjective(\n",
    "    obj_production_cost +\n",
    "    obj_fixed_manu_dc_cost +\n",
    "    obj_fixed_dc_store_cost +\n",
    "    obj_variable_manu_dc_cost +\n",
    "    obj_variable_dc_store_cost,\n",
    "    GRB.MINIMIZE\n",
    ")'''\n",
    "\n",
    "promo_price_factor = [0.19, 0.22] \n",
    "product_price = [15,40]\n",
    "\n",
    "revenue = gp.quicksum(promo[prod_id]*(1-promo_price_factor[prod_id-1])*product_price[prod_id-1] for prod_id in product_name_to_id.values()) + gp.quicksum((1-promo[prod_id])*product_price[prod_id-1] for prod_id in product_name_to_id.values())\n",
    "\n",
    "promo_fixed_cost = [50000,133333]\n",
    "\n",
    "promo_fixed_cost_total = gp.quicksum(promo_fixed_cost[prod_id-1] * promo[prod_id] for prod_id in product_name_to_id.values())\n",
    "\n",
    "model.setObjective(\n",
    "    revenue -\n",
    "    (obj_production_cost +\n",
    "    obj_fixed_manu_dc_cost +\n",
    "    obj_fixed_dc_store_cost +\n",
    "    obj_variable_manu_dc_cost +\n",
    "    obj_variable_dc_store_cost + \n",
    "    promo_fixed_cost_total),\n",
    "    GRB.MAXIMIZE\n",
    ")\n",
    "\n",
    "print(\"--- Objective Function Set (Minimize Total Cost) --- \\n\")\n",
    "\n",
    "# --- 6. Add Constraints ---\n",
    "\n",
    "# Constraint 1: Manufacturer Production Capacity\n",
    "# The total quantity of all products produced by a manufacturer cannot exceed its capacity.\n",
    "# Sum(i in PRODUCTS) x_ij <= manufacturer_capacity[j] for all j in MANUFACTURERS\n",
    "for mfg_id in mfg_name_to_id.values():\n",
    "    model.addConstr(\n",
    "        gp.quicksum(x_ij[prod_id, mfg_id] for prod_id in product_name_to_id.values()) <= manufacturer_capacity[mfg_id],\n",
    "        f\"ManuCapacity_{id_to_mfg_name[mfg_id]}\"\n",
    "    )\n",
    "\n",
    "# Constraint 2: Production must be distributed from Manufacturer\n",
    "# The total amount of product 'i' produced by manufacturer 'j' must be equal to\n",
    "# the total amount of product 'i' shipped from manufacturer 'j' to all DCs.\n",
    "# x_ij == Sum(k in DCS) trans_ijk[i,j,k] for all i in PRODUCTS, j in MANUFACTURERS\n",
    "for prod_id in product_name_to_id.values():\n",
    "    for mfg_id in mfg_name_to_id.values():\n",
    "        model.addConstr(\n",
    "            x_ij[prod_id, mfg_id] == gp.quicksum(trans_ijk[prod_id, mfg_id, dc_id] for dc_id in dc_name_to_id.values()),\n",
    "            f\"ManuOutputFlow_{id_to_product_name[prod_id]}_{id_to_mfg_name[mfg_id]}\"\n",
    "        )\n",
    "\n",
    "# Constraint 3: DC Inbound Capacity\n",
    "# The total quantity of all products flowing into a DC cannot exceed its capacity.\n",
    "# Sum(i in PRODUCTS, j in MANUFACTURERS) trans_ijk <= dc_capacity[k] for all k in DCS\n",
    "for dc_id in dc_name_to_id.values():\n",
    "    model.addConstr(\n",
    "        gp.quicksum(trans_ijk[prod_id, mfg_id, dc_id] for prod_id in product_name_to_id.values() for mfg_id in mfg_name_to_id.values()) <= dc_capacity[dc_id],\n",
    "        f\"DCInboundCapacity_{id_to_dc_name[dc_id]}\"\n",
    "    )\n",
    "\n",
    "# Constraint 4: Flow Balance at DC\n",
    "# For each product 'i' and DC 'k', the total inflow from manufacturers must equal\n",
    "# the total outflow to stores.\n",
    "# Sum(j in MANUFACTURERS) trans_ijk == Sum(e in STORES) trans_ike for all i in PRODUCTS, k in DCS\n",
    "for prod_id in product_name_to_id.values():\n",
    "    for dc_id in dc_name_to_id.values():\n",
    "        model.addConstr(\n",
    "            gp.quicksum(trans_ijk[prod_id, mfg_id, dc_id] for mfg_id in mfg_name_to_id.values()) == gp.quicksum(trans_ike[prod_id, dc_id, store_id] for store_id in store_name_to_id.values()),\n",
    "            f\"DCFlowBalance_{id_to_product_name[prod_id]}_{id_to_dc_name[dc_id]}\"\n",
    "        )\n",
    "\n",
    "promo_demand_factor = [0.63,0.7] #EXTENSION DATA\n",
    "\n",
    "# Constraint 5: Store Demand Fulfillment\n",
    "# For each product 'i' and store 'e', the total quantity received from all DCs\n",
    "# must be at least the store's demand for that product.\n",
    "# Sum(k in DCS) trans_ike >= store_demand[i,e] for all i in PRODUCTS, e in STORES\n",
    "for prod_id in product_name_to_id.values():\n",
    "    for store_id in store_name_to_id.values():\n",
    "        model.addConstr(\n",
    "            gp.quicksum(trans_ike[prod_id, dc_id, store_id] for dc_id in dc_name_to_id.values()) >= (1+promo_demand_factor[prod_id-1]*promo[prod_id]) * store_demand[prod_id, store_id],\n",
    "            f\"StoreDemand_{id_to_product_name[prod_id]}_{id_to_store_name[store_id]}\"\n",
    "        )\n",
    "\n",
    "# Constraint 6: Store Capacity (Inbound)\n",
    "# The total quantity of all products flowing into a store cannot exceed its capacity.\n",
    "# Sum(i in PRODUCTS, k in DCS) trans_ike <= store_capacity[e] for all e in STORES\n",
    "for store_id in store_name_to_id.values():\n",
    "    model.addConstr(\n",
    "        gp.quicksum(trans_ike[prod_id, dc_id, store_id] for prod_id in product_name_to_id.values() for dc_id in dc_name_to_id.values()) <= store_capacity[store_id],\n",
    "        f\"StoreCapacityInbound_{id_to_store_name[store_id]}\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Constraint 7: Linking Manufacturer-DC Flow to Route Activation (Big-M constraint)\n",
    "# If a manufacturer-DC route (j, k) is not open (y_jk = 0), then no product can flow through it.\n",
    "# If it is open (y_jk = 1), flow up to BIG_M (a very large number) is allowed.\n",
    "# trans_ijk <= BIG_M * y_jk[j,k] for all i, j, k\n",
    "for prod_id in product_name_to_id.values():\n",
    "    for mfg_id in mfg_name_to_id.values():\n",
    "        for dc_id in dc_name_to_id.values():\n",
    "            model.addConstr(\n",
    "                trans_ijk[prod_id, mfg_id, dc_id] <= BIG_M * y_jk[mfg_id, dc_id],\n",
    "                f\"Link_ManuDC_Flow_{id_to_product_name[prod_id]}_{id_to_mfg_name[mfg_id]}_{id_to_dc_name[dc_id]}\"\n",
    "            )\n",
    "\n",
    "# Constraint 8: Linking DC-Store Flow to Route Activation (Big-M constraint)\n",
    "# Similar to Constraint 7, but for DC-Store routes.\n",
    "# trans_ike <= BIG_M * z_ke[k,e] for all i, k, e\n",
    "for prod_id in product_name_to_id.values():\n",
    "    for dc_id in dc_name_to_id.values():\n",
    "        for store_id in store_name_to_id.values():\n",
    "            model.addConstr(\n",
    "                trans_ike[prod_id, dc_id, store_id] <= BIG_M * z_ke[dc_id, store_id],\n",
    "                f\"Link_DCStore_Flow_{id_to_product_name[prod_id]}_{id_to_dc_name[dc_id]}_{id_to_store_name[store_id]}\"\n",
    "            )\n",
    "\n",
    "print(\"--- Constraints Added --- \\n\")\n",
    "\n",
    "# --- 7. Optimize the Model ---\n",
    "model.optimize()\n",
    "\n",
    "# --- 8. Print Results ---\n",
    "print(\"\\n--- Optimization Results ---\")\n",
    "\n",
    "if model.status == GRB.OPTIMAL:\n",
    "    print(f\"Optimal Total Cost: ${model.objVal:,.2f}\\n\")\n",
    "\n",
    "    print(\"--- Production by Manufacturer (x_ij) ---\")\n",
    "    for prod_id in product_name_to_id.values():\n",
    "        for mfg_id in mfg_name_to_id.values():\n",
    "            if x_ij[prod_id, mfg_id].x > 1e-6: # Check for non-zero production\n",
    "                print(f\"  {id_to_product_name[prod_id]} produced by {id_to_mfg_name[mfg_id]}: {x_ij[prod_id, mfg_id].x:,.2f} units\")\n",
    "\n",
    "    print(\"\\n--- Manufacturer-DC Routes Open (y_jk) ---\")\n",
    "    for mfg_id in mfg_name_to_id.values():\n",
    "        for dc_id in dc_name_to_id.values():\n",
    "            if y_jk[mfg_id, dc_id].x > 0.5: # Check if binary variable is essentially 1\n",
    "                print(f\"  Route from {id_to_mfg_name[mfg_id]} to {id_to_dc_name[dc_id]} is OPEN\")\n",
    "\n",
    "    print(\"\\n--- Flow from Manufacturers to DCs (trans_ijk) ---\")\n",
    "    for prod_id in product_name_to_id.values():\n",
    "        for mfg_id in mfg_name_to_id.values():\n",
    "            for dc_id in dc_name_to_id.values():\n",
    "                if trans_ijk[prod_id, mfg_id, dc_id].x > 1e-6: # Check for non-zero flow\n",
    "                    print(f\"  {id_to_product_name[prod_id]} from {id_to_mfg_name[mfg_id]} to {id_to_dc_name[dc_id]}: {trans_ijk[prod_id, mfg_id, dc_id].x:,.2f} units\")\n",
    "\n",
    "    print(\"\\n--- DC-Store Routes Open (z_ke) ---\")\n",
    "    for dc_id in dc_name_to_id.values():\n",
    "        for store_id in store_name_to_id.values():\n",
    "            if z_ke[dc_id, store_id].x > 0.5: # Check if binary variable is essentially 1\n",
    "                print(f\"  Route from {id_to_dc_name[dc_id]} to {id_to_store_name[store_id]} is OPEN\")\n",
    "\n",
    "    print(\"\\n--- Flow from DCs to Stores (trans_ike) ---\")\n",
    "    for prod_id in product_name_to_id.values():\n",
    "        for dc_id in dc_name_to_id.values():\n",
    "            for store_id in store_name_to_id.values():\n",
    "                if trans_ike[prod_id, dc_id, store_id].x > 1e-6: # Check for non-zero flow\n",
    "                    print(f\"  {id_to_product_name[prod_id]} from {id_to_dc_name[dc_id]} to {id_to_store_name[store_id]}: {trans_ike[prod_id, dc_id, store_id].x:,.2f} units\")\n",
    "\n",
    "elif model.status == GRB.INFEASIBLE:\n",
    "    print(\"The model is INFEASIBLE. No solution satisfies all constraints.\")\n",
    "    print(\"Consider reviewing your data and constraints for contradictions.\")\n",
    "elif model.status == GRB.UNBOUNDED:\n",
    "    print(\"The model is UNBOUNDED. The objective can be arbitrarily improved.\")\n",
    "    print(\"This often means a necessary constraint or bound is missing.\")\n",
    "else:\n",
    "    print(f\"Optimization ended with status: {model.status}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
